
<script src="http://www.google.com/jsapi" type="text/javascript"></script>
<script type="text/javascript">google.load("jquery", "1.3.2");</script>

<style type="text/css">
    
    body {
        font-family: "HelveticaNeue-Light", "Helvetica Neue Light", "Helvetica Neue", Helvetica, Arial, "Lucida Grande", sans-serif;
        font-weight:300;
        font-size:18px;
        margin-left: auto;
        margin-right: auto;
        width: 1100px;
    }
 
    .box{
        width:1020px;
        margin:0 auto;
        position:relative;
    }
    .box .left{
        width:340px;
        /* height:300px; */
        /* background-color:#eee; */
        position:absolute;
       
    }
    .box .center{
        width:340px;
        /* height:300px; */
        /* background-color:#eee; */
        margin:0 auto;
    }
    .box .right{
        width:340px;
        /* height:300px; */
        /* background-color:#eee; */
        position:absolute;
        right:0;
        top:0;
 
    }
    .box_two{
        width:900px;
        margin:0 auto;
        position:relative;
    }
    .box_two .left{
        width:450px;
        /* height:300px; */
        /* background-color:#eee; */
        position:absolute;
       
    }

    .box_two .right{
        width:450px;
        /* height:300px; */
        /* background-color:#eee; */
        position:absolute;
        right:0;
        top:0;
 
    }


    h1 {
        font-weight:300;
        margin: 0.4em;
    }

    p {
        margin: 0.2em;
    }

    .disclaimerbox {
        background-color: #eee;
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
        padding: 20px;
    }

    video.header-vid {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.header-img {
        height: 140px;
        border: 1px solid black;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    img.rounded {
        border: 1px solid #eeeeee;
        border-radius: 10px ;
        -moz-border-radius: 10px ;
        -webkit-border-radius: 10px ;
    }

    a:link,a:visited
    {
        color: #1367a7;
        text-decoration: none;
    }
    a:hover {
        color: #208799;
    }

    td.dl-link {
        height: 160px;
        text-align: center;
        font-size: 22px;
    }

    /* 图片的重叠 */

    .layered-paper-big { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35), /* The third layer shadow */
                15px 15px 0 0px #fff, /* The fourth layer */
                15px 15px 1px 1px rgba(0,0,0,0.35), /* The fourth layer shadow */
                20px 20px 0 0px #fff, /* The fifth layer */
                20px 20px 1px 1px rgba(0,0,0,0.35), /* The fifth layer shadow */
                25px 25px 0 0px #fff, /* The fifth layer */
                25px 25px 1px 1px rgba(0,0,0,0.35); /* The fifth layer shadow */
        margin-left: 10px;
        margin-right: 45px;
    }


    .layered-paper { /* modified from: http://css-tricks.com/snippets/css/layered-paper/ */
        box-shadow:
                0px 0px 1px 1px rgba(0,0,0,0.35), /* The top layer shadow */
                5px 5px 0 0px #fff, /* The second layer */
                5px 5px 1px 1px rgba(0,0,0,0.35), /* The second layer shadow */
                10px 10px 0 0px #fff, /* The third layer */
                10px 10px 1px 1px rgba(0,0,0,0.35); /* The third layer shadow */
        margin-top: 5px;
        margin-left: 10px;
        margin-right: 30px;
        margin-bottom: 5px;
    }

    .vert-cent {
        position: relative;
        top: 50%;
        transform: translateY(-50%);
    }

    hr
    {
        margin: 0;
        border: 0;
        height: 1.5px;
        background-image: linear-gradient(to right, rgba(0, 0, 0, 0), rgba(0, 0, 0, 0.75), rgba(0, 0, 0, 0));
    }
</style>

<html>
    <head>
        <title>Diff-HMR</title>
    </head>
    

    <body>
	    
        <br>
        <center>
            <span style="font-size:42px">Diff-HMR: Toward More Reliable Human Pose and Shape Estimation from Monocular Video</span>
        </center>
        <br>
	    
	<br> <!-- 换行-->
        <table align=center width=700px>
            <tr>
                    <td align=center width=100px>
                        
                        <a href="https://github.com/wuchuuq/Diff-HMR">[Code]</a>
                            </span>
                        </center>
                </td>
            </tr>
        </table> 
        <br> <!-- 换行-->
        <!-- framework -->
        <table align=center width=900px>
            	<tr>
	        	<td>
                    		<center>                      
		        		<img src = "./framework_update_2.png" width="1080px"></img>
                        		<span style="font-size:15px;font-style:italic">    The overview of our proposed framework. </span>
                    		</center>
                	</td> 
	    	</tr>
        </table>
        <!-- abstract-->
    	<table align=center width=900px></table>
            <tr>
                <td width=600px>
                    <br>
                    <p align="justify" style="font-size: 18px">
                        The accurate recovery of 3D human shape and pose from monocular videos is crucial for understanding human behavior in various media. However, current methods have yet to address the uncertainties inherent in 3D estimation, such as deep ambiguity, blurring, and occlusion, resulting in inaccurate estimates particularly in complex scenarios. To overcome this challenge, we propose a novel Diffusion-based Human Mesh Recovery (Diff-HMR) network. Specifically, our approach incorporates a Diffusion-based Pose Regressor (DPR), which models the estimation of a deterministic pose as a reverse diffusion process. This allows for the stepwise mitigation of uncertainty through denoising. In addition, our Cross-Temporal Attention Module (CTAM) aggregates contextual features as a condition for the reverse diffusion process, guiding the diffusion model towards accurate recovery. To impose more stringent constraints on the recovered vertex positions, we designed a vertex constraint loss that enhances the precision of the estimated human mesh.
Experimental results demonstrate that Diff-HMR outperforms state-of-the-art video-based methods on two benchmarks, 3DPW and Human3.6M. 
                        
                    </tr>
	
    </br>
    </div> 
    </br>
    <hr>   
    <center><h1>Visual comparison of Diff-HMR with other state-of-the-art methods </h1></center>
    
    <!-- demo comparison-->
    <div class="box">
        <div class="left">
            <video id="video2" width="320" style= "margin-top:10px; margin-right:20px;">
                <source src="mps_han_short_output.mp4" type="video/mp4" />
            </video>                
        </div>
        <div class="center">
            <video id="video1" width="320" style= "margin-top:10px;">
                <source src="DIFF_han_short_output.mp4" type="video/mp4" />
            </video>
        </div>
        <div class="right">
            <video id="video3" width="320" style= "margin-top:10px; margin-right:20px;">
                <source src="tcmr_han_short_output.mp4" type="video/mp4" />
            </video>
        </div>
    </div> 
    <center><button onclick= "play_Pause();" style= "margin-top:10px;">play/pause</button></center>

    <script type="text/javascript">
    var myVideo=document.getElementById ("video1");
    var myVideo2=document.getElementById ("video2");
    var myVideo3=document.getElementById ("video3");
    function play_Pause() {
        if (myVideo.paused){
            myVideo.play();
            myVideo2.play();
            myVideo3.play();
        }
        else{
            myVideo.pause();
            myVideo2.pause();
            myVideo3.pause();
        }
    }
    </script>
    
    </br>
    <center>
    <span style="font-size:14px">  
        Given a challenging video which contains fast motion, self occlusion and blurring, Diff-HMR(middle) predicts more accurate result than TCMR [4] (right) and MPS-Net [40] (left), particularly in cases of ambiguity and when estimating figure orientation.
     </span>
    </center>
    
    </br>
    <!-- 3DPW comparison-->
    <div class="box">
        <div class="left">
            <video id="video_l" width="320" style= "margin-top:10px; margin-right:20px;">
                <source src="mps_slalom_output.mp4" type="video/mp4" />
            </video>                
        </div>
        <div class="center">
            <video id="video_c" width="320" style= "margin-top:10px;">
                <source src="diff_slalom_output.mp4" type="video/mp4" />
            </video>
        </div>
        <div class="right">
            <video id="video_r" width="320" style= "margin-top:10px; margin-right:20px;">
                <source src="tcmr_slalom_output.mp4" type="video/mp4" />
            </video>
        </div>
    </div> 
    <center><button onclick= "play_Pause_2();" style= "margin-top:10px;">play/pause</button></center>

    <script type="text/javascript">
    var myVideo_l=document.getElementById ("video_l");
    var myVideo_c=document.getElementById ("video_c");
    var myVideo_r=document.getElementById ("video_r");
    function play_Pause_2() {
        if (myVideo_c.paused){
            myVideo_l.play();
            myVideo_c.play();
            myVideo_r.play();
        }
        else{
            myVideo_l.pause();
            myVideo_c.pause();
            myVideo_r.pause();
        }
    }
    </script>

    </br>
    <!-- Description-->    
    </tr>
        <center>
	    <span style="font-size:14px">   
            Qualitative comparison between Diff-HMR(middle), MPS-Net [40] (left) and TCMR [4] (right) on the challenging in-the-wild dataset 3DPW[38]. For the video which contains occlusion and fast motion, Diff-HMR produces better results than the other two.
          
        </span>
 	</center>
</br>
<hr>
<table align=center width=900px>
            <center><h1>Demo Videos (Diff-HMR)</h1></center>
            <center>
	    <span style="font-size:14px">   
            All the demos are taken from video sites where no similar samples have been trained, thus proving the generalizability of our model.  
        </span>
 	</center>
    <br>
            <tr>
	        <center>
                    <a href="./mp4_compare.mp4">
                        <video width="900" controls preload>
                            <source src="./mp4_compare.mp4" type="video/mp4">
                        </video>
                    </a><br>	
		    <span style="font-size:16px"> Original video frame rate: 24.72fps </span>
                </center>		
		<br>
                <center>
                    <a href="./demo_compare.mp4">
                        <video width="900" controls preload>
                            <source src="./demo_compare.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <span style="font-size:16px"> Original video frame rate: 29.97fps </span>
                </center>
		<br>
                <center>
                    <a href="./mp3_compare.mp4">
                        <video width="900" controls preload>
                            <source src="./mp3_compare.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <span style="font-size:16px"> Original video frame rate: 24.72fps </span>
                </center> 
		<br>
		<center>
                    <a href="./visual4-compare.mp4">
                        <video width="500" controls preload>
                            <source src="./visual4-compare.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <span style="font-size:16px"> Original video frame rate: 24.78fps </span>
                </center>

        <br>
		<center>
                    <a href="./visual1_compare.mp4">
                        <video width="500" controls preload>
                            <source src="./visual1_compare.mp4" type="video/mp4">
                        </video>
                    </a><br>
		    <span style="font-size:16px"> Original video frame rate: 24.68fps </span>
                </center>
	    </tr>
        
    </table>
    
    <br>
    <hr> 
        <table align=center width=900px>
            <center><h1>Visual effects of Diff-HMR in alternative viewpoints</h1></center>
            <tr>
                    <center>
                        <a href="./visual2.png"><img src = "./visual2.png" width="900px"></img></a><br>
                    </center><br>
		    <center>
                        <a href="./visual3.png"><img src = "./visual3.png" width="900px"></img></a><br>
                    </center><br>
		    <center>
                        <!-- <a href="./LSPchoice360.gif"><img src = "./LSPchoice360.gif" width="900px"></img></a><br>
		        <span style="font-size:14px">   <b>We visualize the 3D human body estimated by our MPS-Net from different viewpoints.</b> The results show that our MPS-Net is able to estimate the correct global body rotation. </span>
                    </center> -->
            </tr>
        </table>  
        
        
    
	<br>
        <hr>
        <center><h1>Qualitative Results</h1></center>
             <tr>
                 <th colspan='4'>
                   <center>
                     <span style="font-size:22px">Details of visual comparison between Diff-HMR (middle), MPS-Net (top) and TCMR (bottom)</span>
                   </center>
                 </th>
             </tr>
        <br>
        <table align=center width=900px>
        	<tr>
			<center>
				<a href="./compare_1.png"><img src = "./compare_1.png" width="900px"></img></a><br>
                                <!--<span style="font-size:14px">
                     			Qualitative comparison of TCMR [6] (left) and our MPS-Net (right) on the challenging in-the-wild 3DPW [37] and MPI-INF-3DHP [27] datasets.
                    		</span>-->
                    	</center><br>
		</tr>       
        
        <hr>   
	
	
	<br>
        <br>
        <!-- <hr> -->
        <!--<a name="related_work"></a>-->
 	<!-- <table align=center width=1100px>
 	    <tr>
		<td width=400px> -->
 			<!--<left>-->
  		  	<!-- <center>
				<h1>Contact Information</h1>
				Wen-Li Wei, Jen-Chun Lin {lilijinjin@gmail.com; jenchunlin@gmail.com}
			</center>
		</td>
	    </tr>
	</table> -->
	<br>
        <br>
        <hr>
	<!-- <table align=center width=1100px>
 	    <tr>
		<td width=400px> -->
 			<!--<left>-->
  		  	<!-- <center>
				<h1>Acknowledgements</h1>
				This webpage template was refered from Phillip Isola and Richard Zhang. Thanks a lot.
			</center>
		</td>
	    </tr>
	</table> -->
    </body>
</html>
